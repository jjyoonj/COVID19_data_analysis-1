{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image crawling",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLstdXxfdsCFcoteQx6zqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeongyoon-Jang/COVID19_data_analysis-1/blob/main/Image_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8IfBTBvQFsa"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "from urllib.parse import quote_plus    # korean support\n",
        "from bs4 import BeautifulSoup as BS    # Essential module\n",
        "from selenium import webdriver         # Google crolling\n",
        "import time\n",
        "\n",
        "keyword = input(\"Input keyword: \")\n",
        "i_URL = f'https://www.google.com/search?q={quote_plus(keyword)}&sxsrf=ALeKk00OQamJ34t56QSInnMzwcC5gC344w:1594968011157&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjXs-7t1tPqAhVF7GEKHfM4DqsQ_AUoAXoECBoQAw&biw=1536&bih=754'\n",
        "\n",
        "driver= webdriver.Chrome('C:/Users/jjyoo/chromedriver.exe')\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
        "driver.get(i_URL)\n",
        "driver.maximize_window()\n",
        "for i in range(500):\n",
        "    driver.execute_script(\"window.scrollBy(0,10000)\")\n",
        "    \n",
        "\n",
        "html = driver.page_source\n",
        "soup = BS(html,features=\"html.parser\")\n",
        "\n",
        "    \n",
        "img = soup.select('.rg_i.Q4LuWd') # img = soup.select('img')\n",
        "\n",
        "i_list = []\n",
        "count = 1\n",
        "\n",
        "for i in img:\n",
        "    try:\n",
        "        i_list.append(i.attrs[\"src\"])\n",
        "    except KeyError:\n",
        "        i_list.append(i.attrs[\"data-src\"])\n",
        "\n",
        "for i in i_list:\n",
        "   urlretrieve(i,\"image/\"+keyword+str(count)+\".jpg\")\n",
        "   count+=1\n",
        "   print(i_list)\n",
        "   if (count == 300):\n",
        "       break\n",
        "   \n",
        "print(\"Downloading...\")\n",
        "\n",
        "\n",
        "driver.close()\n",
        "print(\"FINISH\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}